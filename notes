Streams are a clever idea that allows one to use sequence manipulations without incurring the costs of manipulating sequences as lists. With streams we can achieve the best of both worlds: We can formulate programs elegantly as sequence manipulations, while attaining the efficiency of incremental computation. The basic idea is to arrange to construct a stream only partially, and to pass the partial construction to the program that consumes the stream. If the consumer attempts to access a part of the stream that has not yet been constructed, the stream will automatically construct just enough more of itself to produce the required part, thus preserving the illusion that the entire stream exists. In other words, although we will write programs as if we were processing complete sequences, we design our stream implementation to automatically and transparently interleave the construction of the stream with its use.

SICP Sec 3.5.1

Streams outline

- Streams?

From unix
ex. sed

Simple terminal demo

Streams are a data structure

SICP says “Streams are delayed lists”


Why?
Can’t hold all the things in memory
Bandwidth is expensive

- Streams!!!!

Now I’ll rant a bit about how streams are !! awesome

What if you want to represent a (possibly) infinite data set

STREAMS

WIZARDS

What are things that don’t have an end?
- natural numbers, natural phenomena ex. electromagnetic storms, user input (stdin), large data sets, your heartbeat
Ok maybe an UNKNOWN end

SICP: “Stream processing lets us model systems that have state without ever using assignment or mutable data.”

AWESOME

- Streams in action
example: proxy server (draw)

Two* modes: Push and pull

Push: Firehose, consumer must be able to handle or producer must be slow enough
Generally callbacks
No blocking, downside is you can overload

Pull: Gimme more gimme more
Generally iterators
Blocking, have to timeout if it takes too long (never ever block forever)

pull if they feel producer if too fast
push if they feel like producer is slower or consumer has enough resources to deal (ex. buffering)

pull is more synchronous, can make it really bad for performance (ex. latency between nodes all pulling from each other)

pause/resume is a mixed model

- Streams in JavaScript

Obviously Node streams
simple example of loading file then writing vs. loading file and writing it AS you get it
http://nodestreams.com/
Substack streams handbook
stream-adventure

Generators
Iterator style streams
Show trivial example
Show @getify’s router
HighlandJS

https://github.com/baconjs/bacon.js#creating-streams

Browser streams
Standard in progress??

Next: Reactive Streams:
Akka reactive streams
Demand model (animation maybe to explain?)
Solves the push/pull problem! Performance benefits of push and the safety of pull
https://github.com/reactive-streams/reactive-streams-js/
:(
Soon???

— Thank you!
